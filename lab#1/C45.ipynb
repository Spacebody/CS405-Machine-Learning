{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Yilin Zheng\n",
    "# Date: 18 Sept, 2018\n",
    "# Reference code: https://github.com/AliceDudu/Learning-Notes/blob/master/Machine-Learning-Algorithms/\\\n",
    "#                 DecisionTrees/self-learning-c45algorithm-steps.ipynb\n",
    "\n",
    "from math import log\n",
    "import operator\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class C45:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def preprocess(self, dataset, continus_features):\n",
    "        \"\"\"\n",
    "        preprocess continus data, here I just simple keep the integer part\n",
    "        \"\"\"\n",
    "        pass\n",
    "        for data in dataset:\n",
    "            for feature in continus_features:\n",
    "                data[feature] = int(data[feature])\n",
    "        return dataset\n",
    "    \n",
    "    \n",
    "    def fit(self, dataset, labels, continus_features=None):\n",
    "        \"\"\"\n",
    "        fit data into model\n",
    "        \"\"\"\n",
    "        if continus_features is not None:\n",
    "            dataset = self.preprocess(dataset, continus_features)\n",
    "        return self.create_tree(dataset, labels)\n",
    "    \n",
    "    \n",
    "    def cal_entropy(self, dataset):\n",
    "        \"\"\"\n",
    "        calculate Shannon entropy\n",
    "        \"\"\"\n",
    "        entry_num = len(dataset)\n",
    "        label_counts = {}\n",
    "        for data in dataset:\n",
    "            data_label = data[-1]  # default that the last value of the data is its label\n",
    "            if data_label not in label_counts.keys():\n",
    "                label_counts[data_label] = 0\n",
    "            label_counts[data_label] += 1\n",
    "        entropy = 0.0\n",
    "        for label in label_counts:\n",
    "            prob = float(label_counts[label])/entry_num\n",
    "            entropy -= prob * log(prob, 2)\n",
    "        return entropy\n",
    "    \n",
    "    \n",
    "    def classify_node(self, labels):\n",
    "        \"\"\"\n",
    "        label the node of tree\n",
    "        \"\"\"\n",
    "        label_counts = {}\n",
    "        for label in labels:\n",
    "            if label not in label_counts.keys():\n",
    "                label_count[label] = 0\n",
    "            label_counts[c] += 1\n",
    "        sorted_label_counts = sorted(label_counts.iteritems(), key=operator.itemgetter(1), reversed=True)\n",
    "        return sorted_label_counts[0][0]\n",
    "    \n",
    "    \n",
    "    def select_feature(self, dataset):\n",
    "        \"\"\"\n",
    "        select the best feature to span the brach\n",
    "        \"\"\"\n",
    "        feature_num = len(dataset[0])-1\n",
    "        base_entropy = self.cal_entropy(dataset)\n",
    "        max_entropy_gain_ratio = 0.0\n",
    "        best_feature = -1\n",
    "        for i in range(feature_num):\n",
    "            feature_values = set([data[i] for data in dataset])\n",
    "            new_entrypy = 0.0\n",
    "            split_info = 0.0\n",
    "            for value in feature_values:\n",
    "                subdataset = self.remove_entry(dataset, i, value)\n",
    "                prob = len(subdataset)/float(len(dataset))\n",
    "                new_entrypy += prob * self.cal_entropy(subdataset)\n",
    "                split_info += -prob * log(prob, 2)\n",
    "            entroy_gain = base_entropy - new_entrypy\n",
    "            if (split_info == 0):\n",
    "                continue\n",
    "            entropy_gain_ratio = entroy_gain / split_info\n",
    "            if (entroy_gain > max_entropy_gain_ratio):\n",
    "                max_entropy_gain_ratio = entropy_gain_ratio\n",
    "                best_feature = i\n",
    "        return best_feature\n",
    "\n",
    "    def remove_entry(self, dataset, entry_num, value):\n",
    "        \"\"\"\n",
    "        remove the entry in data, which is used as a label on node\n",
    "        the generated new dataset does not contain any value of used feature\n",
    "        \"\"\"\n",
    "        new_dataset = []\n",
    "        for data in dataset:\n",
    "            if data[entry_num] == value:                \n",
    "                new_data = data[:entry_num] + data[entry_num+1:]  \n",
    "                new_dataset.append(new_data)            \n",
    "        return new_dataset\n",
    "\n",
    "    \n",
    "    def create_tree(self, dataset, labels):\n",
    "        \"\"\"\n",
    "        create tree recursively\n",
    "        \"\"\"\n",
    "        classes = [data[-1] for data in dataset]\n",
    "        if classes.count(classes[0]) == len(classes):\n",
    "            return classes[0]\n",
    "        if len(dataset[0]) == 1:\n",
    "            return self.classify_node(classes)\n",
    "        best_feature = self.select_feature(dataset)\n",
    "        best_feature_label = labels[best_feature]\n",
    "        decision_tree = {best_feature_label:{}}\n",
    "        del(labels[best_feature])\n",
    "        feature_values = set([data[best_feature] for data in dataset])\n",
    "        for value in feature_values:\n",
    "            sublabels = labels[:]\n",
    "            decision_tree[best_feature_label][value] = self.create_tree(self.remove_entry(dataset, best_feature, value),\\\n",
    "                                                                       sublabels)\n",
    "        return decision_tree  \n",
    "\n",
    "    \n",
    "    def predict_a_data(self, decision_tree, test_data, labels):\n",
    "        \"\"\"\n",
    "        predict label for a data\n",
    "        \"\"\"\n",
    "        root_feature = list(decision_tree.keys())[0]\n",
    "        second_dict = decision_tree[root_feature]\n",
    "        feature_index = labels.index(root_feature)\n",
    "        feature_label = None\n",
    "        for key in second_dict.keys():\n",
    "            if test_data[feature_index] == key:\n",
    "                if type(second_dict[key]).__name__ == 'dict': \n",
    "                    feature_label = self.predict_a_data(second_dict[key], test_data, labels)\n",
    "                else:\n",
    "                    feature_label = second_dict[key]      \n",
    "        return feature_label\n",
    "    \n",
    "\n",
    "    def predict(self, decision_tree, test_dataset, labels):\n",
    "        \"\"\"\n",
    "        predict labels for all data\n",
    "        \"\"\"\n",
    "        feature_label_all = []\n",
    "        for test_data in test_dataset:\n",
    "            feature_label_all.append(self.predict_a_data(decision_tree, test_data, labels))\n",
    "        return feature_label_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'outlook': {0: 'N', 1: 'Y', 2: {'windy': {0: 'Y', 1: 'N'}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['N', 'N', 'Y', 'N', 'Y', 'Y', 'N']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataSet = [[0, 0, 0, 0, 'N'],\n",
    "           [0, 0, 0, 1, 'N'], \n",
    "           [1, 0, 0, 0, 'Y'], \n",
    "           [2, 1, 0, 0, 'Y'], \n",
    "           [2, 2, 1, 0, 'Y'], \n",
    "           [2, 2, 1, 1, 'N'], \n",
    "           [1, 2, 1, 1, 'Y']]\n",
    "\n",
    "labels = ['outlook', 'temperature', 'humidity', 'windy']\n",
    "\n",
    "\n",
    "testSet = [[0, 1, 0, 0], \n",
    "           [0, 2, 1, 0], \n",
    "           [2, 1, 1, 0], \n",
    "           [0, 1, 1, 1], \n",
    "           [1, 1, 0, 1], \n",
    "           [1, 0, 1, 0], \n",
    "           [2, 1, 0, 1]]\n",
    "\n",
    "\n",
    "\n",
    "model = C45()\n",
    "labels_tmp = labels[:]\n",
    "tree = model.fit(dataSet, labels_tmp)\n",
    "print(tree)\n",
    "labels_tmp2 = labels[:]\n",
    "y_pred = model.predict_a_data(tree, testSet[0], labels_tmp2)\n",
    "display(y_pred)\n",
    "labels_tmp3 = labels[:]\n",
    "y_pred = model.predict(tree, testSet, labels_tmp3)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_table('train.txt', delim_whitespace=True, header=None, skip_blank_lines=True)\n",
    "# display(dataset)\n",
    "\n",
    "labels = dataset.columns.values.tolist()\n",
    "dataset = list(dataset.values.tolist())\n",
    "continus = [2, 3, 4, 14, 17, 18, 20]\n",
    "\n",
    "dt = C45()\n",
    "labels_tmp4 = labels[:]\n",
    "tree = dt.fit(dataset, labels_tmp4, continus)\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
